{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3fc10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime, timedelta\n",
    "import math\n",
    "import re\n",
    "pd.options.mode.chained_assignment = None\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbcb29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file\n",
    "chemicalFormulation = pd.read_csv('C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\chemicalFormulation.csv', encoding='cp1252')\n",
    "chemicalForecastData = pd.read_csv('C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\salesForecast.csv', encoding='cp1252')\n",
    "chemicalStock = pd.read_csv('C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\chemicalStock.csv', encoding='cp1252')\n",
    "chemicalInfo_Intransit = pd.read_csv('C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\chemicalInfo_Intransit.csv', encoding='cp1252')\n",
    "historyConsumption = pd.read_csv('C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\historyConsumption.csv', encoding='cp1252')\n",
    "curretnOrders = pd.read_excel(open('L:\\\\PLANNING\\\\Lê Tín\\\\JBS Planning Next 2023.xlsx','rb'), sheet_name='Orders Plan')\n",
    "ETA_update = pd.read_excel(open('C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\Chemical planning 2023.xls','rb'), sheet_name='Sheet1')\n",
    "\n",
    "# CURRENT SALES ORDER INFACTORY\n",
    "# get out all the NaN from Sales Order Columns\n",
    "curretnOrders= curretnOrders[curretnOrders['S/O'].notnull()]\n",
    "\n",
    "# get three days ago timeline\n",
    "threeDaysAgo = datetime.now() - timedelta(days=3)\n",
    "\n",
    "# function to get the articles name\n",
    "def getArticles(data_df):\n",
    "    match_object = re.findall(r'\\w+-\\w\\s(\\w+-?\\w+)', data_df['ART.'])\n",
    "    if len(match_object)>0:\n",
    "        return match_object[0]\n",
    "    else:\n",
    "        return \"Can Not Match The Name\"\n",
    "curretnOrders['family_Articles'] = curretnOrders.apply(getArticles, axis=1)\n",
    "\n",
    "# get neccessary column\n",
    "curretnOrders = curretnOrders[['family_Articles', 'SF (Already +15%)','DE.DATE']]\n",
    "\n",
    "# convert to datetime\n",
    "curretnOrders['DE.DATE'] = pd.to_datetime(curretnOrders['DE.DATE'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# fill all NaT to current time\n",
    "curretnOrders[['DE.DATE']] = curretnOrders[['DE.DATE']].fillna(f'{datetime.now()}')\n",
    "\n",
    "# filter data from 3days ago onwards\n",
    "curretnOrders = curretnOrders.loc[curretnOrders['DE.DATE']>threeDaysAgo]\n",
    "\n",
    "# group the articles demand on articles name\n",
    "curretnOrders = pd.DataFrame({'sf.' : curretnOrders.groupby(['family_Articles'])['SF (Already +15%)'].sum()}).reset_index()\n",
    "\n",
    "# ----------------------\n",
    "\n",
    "# GET UPDATE FOR INTRANSIT\n",
    "# get out all the NaN from Code\n",
    "ETA_update = ETA_update[ETA_update['Code'].notnull()]\n",
    "\n",
    "# get columns list\n",
    "ETA_columns = ETA_update.columns.tolist()\n",
    "\n",
    "# trim all columns and assign back to dataframe\n",
    "ETA_columns = [col.strip() for col in ETA_columns]\n",
    "ETA_update.set_axis(ETA_columns, axis=1, inplace=True)\n",
    "ETA_update = ETA_update.loc[ETA_update['Shoe/Fur']=='Fur']\n",
    "\n",
    "# change data type of \"ETA Vietnam PORT\" to string\n",
    "ETA_update = ETA_update.astype({'ETA Vietnam PORT':'str', 'Shipping Qty':'str'})\n",
    "\n",
    "# combine quantity with ETA\n",
    "ETA_update['toVNport'] = ETA_update[[\"ETA Vietnam PORT\", \"Shipping Qty\"]].apply(\"::\".join, axis=1)\n",
    "\n",
    "# convert back Shipping Qty back to float\n",
    "ETA_update = ETA_update.astype({'Shipping Qty':'float'})\n",
    "\n",
    "# combine all ETA in one row and group all same chemical\n",
    "ETA_quantity = ETA_update.groupby(['Code'])['Shipping Qty'].sum().reset_index()\n",
    "ETA_shipment = ETA_update.groupby(['Code'])['toVNport'].apply(lambda x: '|||'.join(x)).reset_index()\n",
    "\n",
    "# combine all ETA, quantity for one chemical\n",
    "ETA_allCombine = ETA_quantity.merge(ETA_shipment, how='left', on=['Code'])\n",
    "ETA_allCombine.set_axis(['Material','Intransit', 'Intransit_Notes'], axis=1, inplace=True)\n",
    "# --------------------\n",
    "\n",
    "\n",
    "\n",
    "#Get chemical stock\n",
    "chemicalStock = chemicalStock[['Material', 'Storage Location', 'Long Material Description', 'Unrestricted']]\n",
    "chemicalStock = chemicalStock[chemicalStock['Material'] < 1700000]\n",
    "chemicalStock_CH01 = chemicalStock[chemicalStock['Storage Location'] == 'CH01']\n",
    "chemicalStock_CH01 = pd.DataFrame({'Stock_CH01' : round(chemicalStock_CH01.groupby(['Material'])['Unrestricted'].sum(),0)}).reset_index()\n",
    "chemicalStock_CH10 = chemicalStock[chemicalStock['Storage Location'] == 'CH10']\n",
    "chemicalStock_CH10 = pd.DataFrame({'Stock_CH10' : round(chemicalStock_CH10.groupby(['Material'])['Unrestricted'].sum(),0)}).reset_index()\n",
    "\n",
    "# get stock ch01, ch10 to chemicalInfo_Intransit\n",
    "chemicalInfo_Intransit_m01 = chemicalInfo_Intransit.merge(ETA_allCombine, how='left', on=['Material'])\n",
    "chemicalInfo_Intransit_m1 = chemicalInfo_Intransit_m01.merge(chemicalStock_CH01, how='left', on=['Material'])\n",
    "chemicalInfo_Intransit_m2 = chemicalInfo_Intransit_m1.merge(chemicalStock_CH10, how='left', on=['Material'])\n",
    "\n",
    "#Get chemical forecast\n",
    "chemicalFormulation['Quantity'] = chemicalFormulation['Quantity'].apply(lambda x: float(x.replace(',', '').replace('$', '')))\n",
    "chemicalFormulation = chemicalFormulation.astype({'Quantity':'float', 'Component_Description':'str', 'Component':'float'})\n",
    "\n",
    "chemicalFormulation.drop_duplicates(subset=['family_Articles', 'Component_Description', 'Material_Description'], keep='first', inplace=True)\n",
    "\n",
    "# chemicalFormulation.to_csv(\"C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\formulation.csv\")\n",
    "\n",
    "chemicalFormulation['family_Articles'] = chemicalFormulation['family_Articles'].apply(lambda x: x.upper())\n",
    "chemicalForecastData['family_Articles'] = chemicalForecastData['family_Articles'].apply(lambda x: x.upper())\n",
    "curretnOrders['family_Articles'] = curretnOrders['family_Articles'].apply(lambda x: x.upper())\n",
    "\n",
    "G_sfWithoutPigment_Conditions = [\n",
    "    (chemicalFormulation['Step'] == 'PB'),\n",
    "#     (chemicalFormulation['Step'] == 'CC') or (chemicalFormulation['Step'] == 'CC 2') or (chemicalFormulation['Step'] == 'CC 4'),\n",
    "    (chemicalFormulation['Step'] == 'CC') | (chemicalFormulation['Step'] == 'CC 2') | (chemicalFormulation['Step'] == 'CC 4') | (chemicalFormulation['Step'] == 'BC'),\n",
    "#     (chemicalFormulation['Step'] == 'CC 2'),\n",
    "#     (data_df['Step'] == 'CC 4'),\n",
    "    (chemicalFormulation['Step'] == 'FI') | (chemicalFormulation['Step'] == 'FI WA') | (chemicalFormulation['Step'] == 'FI NI') | (chemicalFormulation['Step'] == 'TS'),\n",
    "#     (chemicalFormulation['Step'] == 'FI WA'),\n",
    "#     (data_df['Step'] == 'FI NI'),\n",
    "    (chemicalFormulation['Step'] == 'KE'),\n",
    "    (chemicalFormulation['Step'] == 'EF')]\n",
    "     \n",
    "values = [round(chemicalFormulation['Quantity']*0.9,0), \n",
    "          round(chemicalFormulation['Quantity']*0.86,0),\n",
    "          round(chemicalFormulation['Quantity']*1,0),\n",
    "#           chemicalFormulation['Quantity']*1,\n",
    "#           chemicalFormulation['Quantity']*1,\n",
    "          round(chemicalFormulation['Quantity']*0.95,0),\n",
    "          round(chemicalFormulation['Quantity']*0.93,0),\n",
    "         ]\n",
    "chemicalFormulation['G_sfWithOutPigment'] = np.select(G_sfWithoutPigment_Conditions, values)\n",
    "\n",
    "# merge files formulation with ForecastData, currentOrder\n",
    "chemicalDataWithForecast = chemicalFormulation.merge(chemicalForecastData, how='left', on='family_Articles')\n",
    "chemicalDataWithForecast = chemicalDataWithForecast.merge(curretnOrders, how='left', on='family_Articles')\n",
    "chemicalDataWithForecast = chemicalDataWithForecast.replace(np.nan, 0.0)\n",
    "\n",
    "# get current Demand \n",
    "chemicalDataWithForecast['current Demand'] = round(chemicalDataWithForecast['EFF_Rate']*(chemicalDataWithForecast['G_Sf']*chemicalDataWithForecast['sf.']/1000)*(chemicalDataWithForecast['G_sfWithOutPigment']/1000),0)\n",
    "\n",
    "# get month of chemical forecast\n",
    "months = chemicalForecastData.columns.values.tolist()[1:]\n",
    "\n",
    "for mth in months:\n",
    "    chemicalDataWithForecast[f'{mth}_Forecast'] = round(chemicalDataWithForecast['EFF_Rate']*(chemicalDataWithForecast['G_Sf']*chemicalDataWithForecast[f'{mth}']/1000)*(chemicalDataWithForecast['G_sfWithOutPigment']/1000),0)\n",
    "\n",
    "#Average monthly forecast    \n",
    "months_forecast = chemicalDataWithForecast.columns.values.tolist()[-3:]\n",
    "chemicalDataWithForecast['monthlyForecast'] = round((chemicalDataWithForecast[f'{months_forecast[0]}']+chemicalDataWithForecast[f'{months_forecast[1]}']+chemicalDataWithForecast[f'{months_forecast[2]}'])/3,0)\n",
    "chemicalForecast_onSales = pd.DataFrame({'monthlyForecast' : chemicalDataWithForecast.groupby(['Component'])['monthlyForecast'].sum()}).reset_index()\n",
    "chemicalCurrentDemand = pd.DataFrame({'current Demand' : chemicalDataWithForecast.groupby(['Component'])['current Demand'].sum()}).reset_index()\n",
    "\n",
    "#Info, Intransit, Forecast, current Demand in one file\n",
    "chemicalData_Info_Intransit_Forecast = chemicalInfo_Intransit_m2.merge(chemicalForecast_onSales, how='left', left_on=['Material'], right_on=['Component'])\n",
    "chemicalData_Info_Intransit_Forecast = chemicalData_Info_Intransit_Forecast.merge(chemicalCurrentDemand, how='left', left_on=['Material'], right_on=['Component'])\n",
    "chemicalData_Info_Intransit_Forecast = chemicalData_Info_Intransit_Forecast.drop(['Component_x', 'Component_y'], axis=1)\n",
    "\n",
    "# Functions to get last 6 months as format in data\n",
    "def convertNumToMonth(num):\n",
    "    if num == -5:\n",
    "        mth= 'Jul'\n",
    "    if num == -4:\n",
    "        mth= 'Aug'\n",
    "    if num == -3:\n",
    "        mth= 'Sep'\n",
    "    if num == -2:\n",
    "        mth= 'Oct'\n",
    "    if num == -1:\n",
    "        mth= 'Nov'\n",
    "    if num == 0:\n",
    "        mth= 'Dec'\n",
    "    if num == 1:\n",
    "        mth= 'Jan'\n",
    "    if num == 2:\n",
    "        mth= 'Feb'\n",
    "    if num == 3:\n",
    "        mth= 'Mar'\n",
    "    if num == 4:\n",
    "        mth= 'Apr'\n",
    "    if num == 5:\n",
    "        mth= 'May'\n",
    "    if num == 6:\n",
    "        mth= 'Jun'\n",
    "    if num == 7:\n",
    "        mth= 'Jul'\n",
    "    if num == 8:\n",
    "        mth= 'Aug'\n",
    "    if num == 9:\n",
    "        mth= 'Sep'\n",
    "    if num == 10:\n",
    "        mth= 'Oct'\n",
    "    if num == 11:\n",
    "        mth= 'Nov'\n",
    "    if num == 12:\n",
    "        mth= 'Dec'\n",
    "    return mth\n",
    "def getLast6months(tuday):\n",
    "    mth = tuday.month\n",
    "    yr = tuday.year\n",
    "    m1,m2,m3,m4,m5,m6 = mth-1, mth-2, mth-3, mth-4, mth-5,mth-6\n",
    "    lst6mth = [m1,m2,m3,m4,m5,m6]\n",
    "    lstyr =[]\n",
    "    for mth in lst6mth:\n",
    "        mth_intext = convertNumToMonth(mth)\n",
    "        if mth > 0:\n",
    "            yrConvert=str(yr)[-2:]\n",
    "        else:\n",
    "            yrConvert = str(yr-1)[-2:]\n",
    "        lstyr.append(f'{mth_intext}_{yrConvert}')\n",
    "    return lstyr\n",
    "# get last 6 month Consumption\n",
    "last_6mth = getLast6months(date.today())\n",
    "lst6mth_Consumption = historyConsumption[(historyConsumption['Mon_Year']==f'{last_6mth[0]}') | \n",
    "                                          (historyConsumption['Mon_Year']==f'{last_6mth[1]}') |\n",
    "                                          (historyConsumption['Mon_Year']==f'{last_6mth[2]}') |\n",
    "                                          (historyConsumption['Mon_Year']==f'{last_6mth[3]}') |\n",
    "                                          (historyConsumption['Mon_Year']==f'{last_6mth[4]}') |\n",
    "                                          (historyConsumption['Mon_Year']==f'{last_6mth[5]}')]\n",
    "\n",
    "lst6mth_Consumption_horizontal = pd.pivot_table(lst6mth_Consumption, index= ['Material', 'Component_Description'], columns=['Mon_Year'], values=['Consumption'], aggfunc = 'sum', fill_value = 0 )\n",
    "lst6mth_Consumption_horizontal.columns = lst6mth_Consumption_horizontal.columns.droplevel(0)\n",
    "lst6mth_Consumption_horizontal = lst6mth_Consumption_horizontal.reset_index().rename_axis(None, axis=1)\n",
    "lst6mth_Consumption_horizontal.to_csv(f\"C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\lst6mthConsumptionHorizontal.csv\")\n",
    "\n",
    "#Get chemical MonthlyConsumption\n",
    "col_list = lst6mth_Consumption[[\"Mon_Year\"]]\n",
    "col_list = col_list.drop_duplicates(subset= ['Mon_Year'], keep='first', inplace=False)\n",
    "col_list_count = col_list['Mon_Year'].count()\n",
    "chemicalForecast_onConsumption = pd.DataFrame({'monthlyConsumption' : round(lst6mth_Consumption.groupby(['Material'])['Consumption'].sum()/col_list_count,0)}).reset_index()\n",
    "\n",
    "#Info, Intransit, Forecast, Consumption in one file\n",
    "chemicalData_Info_Intransit_Forecast_Consumption = chemicalData_Info_Intransit_Forecast.merge(chemicalForecast_onConsumption, how='left', on=['Material'])\n",
    "\n",
    "chemicalData_Info_Intransit_Forecast_Consumption[[\"Leadtime\",\"Intransit\",\"Stock_CH01\",\"Stock_CH10\",\"monthlyForecast\", \"monthlyConsumption\",\"current Demand\"]] = chemicalData_Info_Intransit_Forecast_Consumption[[\"Leadtime\",\"Intransit\",\"Stock_CH01\",\"Stock_CH10\",\"monthlyForecast\", \"monthlyConsumption\",\"current Demand\"]].fillna(0)\n",
    "chemicalData_Info_Intransit_Forecast_Consumption[[\"Pigment\", \"Intransit_Notes\", \"Comments\"]] = chemicalData_Info_Intransit_Forecast_Consumption[[\"Pigment\",\"Intransit_Notes\", \"Comments\"]].fillna('-')\n",
    "\n",
    "#Condition to calculate the volumn to buy base on Forecast or Consumption\n",
    "conditions = [\n",
    "    (chemicalData_Info_Intransit_Forecast_Consumption['monthlyForecast'] >= chemicalData_Info_Intransit_Forecast_Consumption['monthlyConsumption']),\n",
    "    (chemicalData_Info_Intransit_Forecast_Consumption['monthlyForecast'] < chemicalData_Info_Intransit_Forecast_Consumption['monthlyConsumption']),\n",
    "]\n",
    "\n",
    "# proposal Consumption balance btw forecast & consumption\n",
    "results_consumption_proposal = [chemicalData_Info_Intransit_Forecast_Consumption['monthlyForecast'],\n",
    "                                chemicalData_Info_Intransit_Forecast_Consumption['monthlyConsumption']]\n",
    "\n",
    "chemicalData_Info_Intransit_Forecast_Consumption['ForeCast_Consumption'] = np.select(conditions, results_consumption_proposal)\n",
    "\n",
    "# Default minumum Stockf (round up to month and plus 1.5)\n",
    "def minStock(data_df):\n",
    "    if data_df['ForeCast_Consumption'] == 0:\n",
    "        return 0\n",
    "    elif data_df['ForeCast_Consumption'] != 0:\n",
    "        return round(data_df['Leadtime']/30 + 1.5,1)\n",
    "    \n",
    "chemicalData_Info_Intransit_Forecast_Consumption['minimumStock_inMonth'] = chemicalData_Info_Intransit_Forecast_Consumption.apply(minStock, axis = 1)\n",
    "# chemicalData_Info_Intransit_Forecast_Consumption['minimumStock_inMonth'] = np.ceil(chemicalData_Info_Intransit_Forecast_Consumption['Leadtime']/30) + 1.5\n",
    "\n",
    "# Current Stock\n",
    "def currentStock(data_df):\n",
    "    if data_df['ForeCast_Consumption'] == 0:\n",
    "        return data_df['Stock_CH01']+data_df['Stock_CH10']+data_df['Intransit']\n",
    "    elif data_df['ForeCast_Consumption'] != 0:\n",
    "        return round((data_df['Stock_CH01']+data_df['Stock_CH10']+data_df['Intransit'])/data_df['ForeCast_Consumption'], 1)\n",
    "\n",
    "chemicalData_Info_Intransit_Forecast_Consumption['CurrentStockInMonth'] = chemicalData_Info_Intransit_Forecast_Consumption.apply(currentStock, axis = 1)\n",
    "# chemicalData_Info_Intransit_Forecast_Consumption['CurrentStockInMonth'] = round((chemicalData_Info_Intransit_Forecast_Consumption['Stock_CH01']+chemicalData_Info_Intransit_Forecast_Consumption['Stock_CH10']+chemicalData_Info_Intransit_Forecast_Consumption['Intransit'])/chemicalData_Info_Intransit_Forecast_Consumption['ForeCast_Consumption'], 1)\n",
    "\n",
    "\n",
    "# BuyToHitMinimumStock\n",
    "chemicalData_Info_Intransit_Forecast_Consumption['BuyToHitMinStock'] = (chemicalData_Info_Intransit_Forecast_Consumption['minimumStock_inMonth'] - chemicalData_Info_Intransit_Forecast_Consumption['CurrentStockInMonth'])*chemicalData_Info_Intransit_Forecast_Consumption['ForeCast_Consumption']\n",
    "chemicalData_Info_Intransit_Forecast_Consumption['BuyToHitMinStock'] = chemicalData_Info_Intransit_Forecast_Consumption['BuyToHitMinStock'].apply(lambda x: x if (x>0) else 0)\n",
    "chemicalData_Info_Intransit_Forecast_Consumption['ByTank'] = round(chemicalData_Info_Intransit_Forecast_Consumption['BuyToHitMinStock']/chemicalData_Info_Intransit_Forecast_Consumption['Tank_Drum_Size'],1)\n",
    "\n",
    "# current Stock vs current orders\n",
    "chemicalData_Info_Intransit_Forecast_Consumption['cur.Stock vs. cur. Order'] = round(chemicalData_Info_Intransit_Forecast_Consumption['Stock_CH01']+chemicalData_Info_Intransit_Forecast_Consumption['Stock_CH10']-chemicalData_Info_Intransit_Forecast_Consumption['current Demand'],0)\n",
    "chemicalData_Info_Intransit_Forecast_Consumption['cur.Stock vs. oneMonth'] = round(chemicalData_Info_Intransit_Forecast_Consumption['Stock_CH01']+chemicalData_Info_Intransit_Forecast_Consumption['Stock_CH10']-chemicalData_Info_Intransit_Forecast_Consumption['ForeCast_Consumption'],0)\n",
    "\n",
    "chemicalData_Info_Intransit_Forecast_Consumption.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "chemicalData_Info_Intransit_Forecast_Consumption[[\"CurrentStockInMonth\"]] = chemicalData_Info_Intransit_Forecast_Consumption[[\"CurrentStockInMonth\"]].fillna(0)\n",
    "chemicalData_Info_Intransit_Forecast_Consumption['revisedToBuy'] = ''\n",
    "chemicalData_Info_Intransit_Forecast_Consumption['stockincludedBuy'] = ''\n",
    "chemicalData_Info_Intransit_Forecast_Consumption = chemicalData_Info_Intransit_Forecast_Consumption[['Material', 'Long Material Description','Supplier','Location', 'Leadtime', 'Tank_Drum_Size', 'Pigment', 'Comments', 'Intransit','Intransit_Notes','Stock_CH01','Stock_CH10', 'monthlyForecast','monthlyConsumption','minimumStock_inMonth','CurrentStockInMonth','BuyToHitMinStock','ByTank', 'revisedToBuy', 'stockincludedBuy', 'ForeCast_Consumption', 'current Demand', 'cur.Stock vs. cur. Order', 'cur.Stock vs. oneMonth']]\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d_%m_%Y%H%M%S\")\n",
    "\n",
    "chemicalData_Info_Intransit_Forecast_Consumption.to_csv(f\"C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\RunSolve\\\\Consolidation_{dt_string}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33e952e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET THE RATE FOR EACH COLOR OF THE ARTICLE\n",
    "# sku_rate = pd.read_excel(open('L:\\\\PLANNING\\\\Lê Tín\\\\BACK-UP\\\\JBS Planning Next 2022.xlsx','rb'), sheet_name='Orders Plan')\n",
    "sku_rate = pd.read_excel(open('C:\\\\Users\\danglc\\\\Desktop\\machineLearning\\\\JBS Planning Next 2022.xlsx','rb'), sheet_name='Orders Plan')\n",
    "sku_rate_col = sku_rate.columns.values.tolist()\n",
    "sku_rate_col = list(map(lambda x: x.strip().upper(), sku_rate_col))\n",
    "sku_rate.set_axis(sku_rate_col, axis='columns', inplace=True)\n",
    "sku_rate= sku_rate[sku_rate['S/O'].notnull()]\n",
    "# function to get the articles name\n",
    "def getArticles(data_df):\n",
    "    match_object = re.findall(r'\\w+-\\w\\s(\\w+-?\\w+)', data_df['ART.'])\n",
    "    if len(match_object)>0:\n",
    "        return match_object[0]\n",
    "    else:\n",
    "        return \"Can Not Match The Name\"\n",
    "sku_rate['FAMILY_ARTICLES'] = sku_rate.apply(getArticles, axis=1)\n",
    "# get neccessary column\n",
    "sku_rate = sku_rate[['FAMILY_ARTICLES', 'COLOR','SF (ALREADY +15%)']]\n",
    "# group the articles demand on articles name\n",
    "sku_rate_groupArtCol = pd.DataFrame({'SF.' : sku_rate.groupby(['FAMILY_ARTICLES', 'COLOR'])['SF (ALREADY +15%)'].sum()}).reset_index()\n",
    "sku_rate_groupArt = pd.DataFrame({'SF.' : sku_rate.groupby(['FAMILY_ARTICLES'])['SF (ALREADY +15%)'].sum()}).reset_index()\n",
    "sku_rate = sku_rate_groupArtCol.merge(sku_rate_groupArt, how='left', on=['FAMILY_ARTICLES'])\n",
    "sku_rate['RATE'] = round(sku_rate['SF._x']/sku_rate['SF._y'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f03beb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LINEA', 'RAVENNA', 'VESUVIUS']\n"
     ]
    }
   ],
   "source": [
    "# CHECK IF ARTICLES IN SALES ALREADY PRODUCED\n",
    "# get sales forecast, strip and upercase column lables\n",
    "salesData = pd.read_csv('C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\salesForecast.csv', encoding='cp1252')\n",
    "salesData_col = salesData.columns.values.tolist()\n",
    "salesData_col = list(map(lambda x: x.strip().upper(), salesData_col))\n",
    "salesData.set_axis(salesData_col, axis='columns', inplace=True)\n",
    "\n",
    "# upper case and check if articles in Sales are in database\n",
    "months = salesData.columns.values.tolist()[1:]\n",
    "salesData['FAMILY_ARTICLES'] = salesData['FAMILY_ARTICLES'].apply(lambda x: x.upper())\n",
    "sale_listArt = salesData['FAMILY_ARTICLES'].tolist()\n",
    "sku_rate_listArt = sku_rate['FAMILY_ARTICLES'].tolist()\n",
    "print([i for i in sale_listArt if i not in sku_rate_listArt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11d36839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET SALES FORECAST BY COLOR\n",
    "salesForecast = sku_rate.merge(salesData, how='left', on=['FAMILY_ARTICLES'])\n",
    "\n",
    "# get volumn sales for each color\n",
    "months = list(map(lambda x: x.strip().upper(), months))\n",
    "for mth in months:\n",
    "    salesForecast[f'{mth}_SF.'] = round(salesForecast[f'{mth}']*salesForecast['RATE'],0)\n",
    "\n",
    "# sort new column\n",
    "sales_col_sort = ['FAMILY_ARTICLES', 'COLOR']\n",
    "for mth in months:\n",
    "    sales_col_sort.append(f'{mth}_SF.')\n",
    "salesForecast = salesForecast[salesForecast.columns.intersection(sales_col_sort)]\n",
    "\n",
    "# asign back to original column name\n",
    "sales_col_srt = ['FAMILY_ARTICLES', 'COLOR']\n",
    "for mth in months:\n",
    "    sales_col_srt.append(mth)\n",
    "salesForecast.set_axis(sales_col_srt, axis='columns', inplace=True)\n",
    "\n",
    "months_forecast = salesForecast.columns.values.tolist()[-3:]\n",
    "salesForecast['monthlyFORECAST'] = round((salesForecast[f'{months_forecast[0]}']+salesForecast[f'{months_forecast[1]}']+salesForecast[f'{months_forecast[2]}'])/3,0)\n",
    "salesForecast= salesForecast[salesForecast['monthlyFORECAST'].notnull()]\n",
    "salesForecast = salesForecast[['FAMILY_ARTICLES', 'COLOR', 'monthlyFORECAST']]\n",
    "salesForecast.to_csv(f\"C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\RunSolveFile\\\\salesForecastColorBreakdown.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "86bfc31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUT BOM INFORMATION IN HORIZONTAL\n",
    "data = pd.read_excel(open('C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\CONTROL BOM.xlsx','rb'), sheet_name='DATA')\n",
    "data_colorCode = data.loc[(data['Material type descr.'] == 'WIP FINISHED')]\n",
    "data_mixture = data.loc[(data['Material type descr.'] == 'MIXTURES AND FORMULATIONS')]\n",
    "data_mixture = data_mixture[['Material', 'Material Description','Component', 'Component Description', 'Component quantity']]\n",
    "# data_colorCode = data.loc[~(data['Material type descr.'] == 'WIP FINISHED')]\n",
    "def getArticles(data_df):\n",
    "    match_object = re.findall(r'\\w+-\\w\\s(\\w+-?\\w+)', data_df['Material Description'])\n",
    "    if len(match_object)>0:\n",
    "        return match_object[0]\n",
    "    else:\n",
    "        return \"Can Not Match The Name\"\n",
    "    \n",
    "def getColorCode(data_df):\n",
    "    match_object = re.findall(r'\\((\\d+)\\)', data_df['Material Description'])\n",
    "    if len(match_object)>0:\n",
    "        return match_object[0]\n",
    "    else:\n",
    "        return \"Can Not Match The Name\"\n",
    "    \n",
    "data_colorCode['colorCode'] = data_colorCode.apply(getColorCode, axis=1)\n",
    "data_colorCode['FAMILY_ARTICLES'] = data_colorCode.apply(getArticles, axis=1)\n",
    "data_colorCode = data_colorCode.loc[~(data_colorCode['colorCode'] == 'Can Not Match The Name')]\n",
    "data_colorCode.drop_duplicates(subset=['FAMILY_ARTICLES', 'Component', 'colorCode'], keep='first', inplace=True)\n",
    "\n",
    "data_colorCode = data_colorCode.merge(data_mixture, how='left', left_on=['Component'], right_on='Material')\n",
    "data_colorCode= data_colorCode[data_colorCode['Component Description_y'].notnull()]\n",
    "data_colorCode = data_colorCode.drop(['Material_y', 'Material Description_y'], axis=1)\n",
    "\n",
    "data_colorCode.set_axis(['Material', 'Material Description', 'BOM status', 'Alternative BOM',\n",
    "       'Item Category', 'Item Number', 'Component',\n",
    "       'Component Description', 'Component quantity', 'Base quantity',\n",
    "       'Material type descr.', 'Created on', 'colorCode', 'FAMILY_ARTICLES','Componenty',\n",
    "       'Component Descriptiony', 'Component quantityy'], axis='columns', inplace=True)\n",
    "\n",
    "data_formulation_base = data_colorCode[data_colorCode[\"Component Descriptiony\"].str.contains(\"FR PIN TBH\")]\n",
    "data_formulation_base = data_formulation_base.merge(data_mixture, how='left', left_on=['Componenty'], right_on='Material')\n",
    "data_formulation_base = data_formulation_base.drop(['Componenty', 'Component Descriptiony','Component quantityy','Material_y','Material Description_y'], axis=1)\n",
    "data_formulation_base.set_axis(['Material', 'Material Description', 'BOM status', 'Alternative BOM',\n",
    "       'Item Category', 'Item Number', 'Component',\n",
    "       'Component Description', 'Component quantity', 'Base quantity',\n",
    "       'Material type descr.', 'Created on', 'colorCode', 'FAMILY_ARTICLES','Componenty',\n",
    "       'Component Descriptiony', 'Component quantityy'], axis='columns', inplace=True)\n",
    "\n",
    "all_formulationData = pd.concat([data_colorCode, data_formulation_base], ignore_index=True)\n",
    "all_formulationData = all_formulationData[~all_formulationData[\"Component Descriptiony\"].str.contains(\"FR PIN TBH\")]\n",
    "# all_formulationData.to_csv(f\"C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\all_formulationData.csv\")\n",
    "\n",
    "# adding Gam per sf to database\n",
    "G_sf_Conditions = [\n",
    "    all_formulationData['Component Description'].str.contains(\"WASH OFF\"),\n",
    "    all_formulationData['Component Description'].str.contains(\"KE TIPSHINE\"),\n",
    "    all_formulationData['Component Description'].str.contains(\" FI WA \"),\n",
    "    all_formulationData['Component Description'].str.contains(\"FI NI DECO\"),\n",
    "    all_formulationData['Component Description'].str.contains(\" PB \"),\n",
    "    all_formulationData['Component Description'].str.contains(\" EMU \"),\n",
    "    all_formulationData['Component Description'].str.contains(\" CC \"),\n",
    "    all_formulationData['Component Description'].str.contains(\" EF \"),    \n",
    "    all_formulationData['Component Description'].str.contains(\" TA \"),\n",
    "    all_formulationData['Component Description'].str.contains(\" BC \"),\n",
    "    all_formulationData['Component Description'].str.contains(\" KE \"),\n",
    "    all_formulationData['Component Description'].str.contains(\" FS \"),\n",
    "    all_formulationData['Component Description'].str.contains(\" FI NI \"),    \n",
    "    all_formulationData['Component Description'].str.contains(\" DYE \"),\n",
    "    all_formulationData['Component Description'].str.contains(\" AGG \"),    \n",
    "    all_formulationData['Component Description'].str.contains(\" WAX \"),\n",
    "    all_formulationData['Component Description'].str.contains(\" SPOT \"),\n",
    "    ]\n",
    "     \n",
    "G_sf_values = [0.9,0.9,5.5,10,4,4,15,7,3.5,18,0.9,4,10,6.5,10,7,3]\n",
    "all_formulationData['G_sf'] = np.select(G_sf_Conditions, G_sf_values)\n",
    "pigments_list = ['ISOLAC', 'OPERA', 'OXY FINE', 'OXY CAR', 'CONTEX']\n",
    "all_formulationData['PIGCOM'] = all_formulationData['Component Descriptiony'].apply(lambda column: 'PIGMENT' if any(pigment in column for pigment in pigments_list) else 'COMPOUND' )\n",
    "\n",
    "all_formulationData.to_csv(f\"C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\RunSolveFile\\\\all_formulationData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "625315c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET RATE FOR PIGMENTS & COMPOUND\n",
    "pigcom_total = pd.DataFrame({'TOTAL' : all_formulationData.groupby(['Component Description', 'PIGCOM'])['Component quantityy'].sum()}).reset_index()\n",
    "pigments_total = pigcom_total.loc[pigcom_total['PIGCOM'] == 'PIGMENT']\n",
    "compound_total = pigcom_total.loc[pigcom_total['PIGCOM'] == 'COMPOUND']\n",
    "pigcom_Rate = compound_total.merge(pigments_total, how='left', on=['Component Description'])\n",
    "pigcom_Rate['PIGCOM_rate'] = round((pigcom_Rate['TOTAL_x'] - pigcom_Rate['TOTAL_y'])/pigcom_Rate['TOTAL_x'],4)\n",
    "pigcom_Rate = pigcom_Rate[['Component Description', 'PIGCOM_rate']]\n",
    "all_formulationData = all_formulationData.merge(pigcom_Rate, how='left', on=['Component Description'])\n",
    "pigcom_cond = [\n",
    "    (all_formulationData['PIGCOM'] == 'PIGMENT'),\n",
    "    (all_formulationData['PIGCOM'] == 'COMPOUND'),]\n",
    "pigcom_choices = [1, all_formulationData['PIGCOM_rate']]\n",
    "all_formulationData['PIGCOM_RATE'] = np.select(pigcom_cond, pigcom_choices, default=np.nan)\n",
    "# fill all with 1\n",
    "all_formulationData[['PIGCOM_RATE']] = all_formulationData[['PIGCOM_RATE']].fillna(1)\n",
    "all_formulationData = all_formulationData.drop(['PIGCOM_rate'], axis=1)\n",
    "all_formulationData = all_formulationData.astype({'colorCode':'float'})\n",
    "all_formulationData.to_csv(f\"C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\RunSolveFile\\\\all_formulationDataWithRatePIGCOM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c8803cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELLINGTON', 'MALDONADO', 'VINTAGE']\n"
     ]
    }
   ],
   "source": [
    "# CHECK IF ARTICLES IN SALES FORECAST LIST CONTAINED IN DATABASE\n",
    "def lstNoDuplication(x):\n",
    "  return list(dict.fromkeys(x))\n",
    "\n",
    "sale_listArt = salesForecast['FAMILY_ARTICLES'].tolist()\n",
    "data_listArt = all_formulationData['FAMILY_ARTICLES'].tolist()\n",
    "\n",
    "sale_listArt = lstNoDuplication(sale_listArt)\n",
    "data_listArt = lstNoDuplication(data_listArt)\n",
    "print([i for i in sale_listArt if i not in data_listArt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea29a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTION ON THE ARTICLE NAME IF IT MISMATCH COMPARING TO DATABASE ARTICLE NAME\n",
    "missArt_lst = ['ELLI', 'MALD', 'VINT']\n",
    "def matcher(col):\n",
    "    for i in missArt_lst:\n",
    "        if i.upper() in col:\n",
    "            return i\n",
    "    else:\n",
    "        return col\n",
    "salesForecast['FAMILY_ARTICLES'] = salesForecast['FAMILY_ARTICLES'].apply(matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f9cabcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# DOUBLE CHECK IF ARTICLES IN FORECAST ALREADY CONTAINED IN DATABASE AFTER ALIGNMENT\n",
    "def lstNoDuplication(x):\n",
    "  return list(dict.fromkeys(x))\n",
    "\n",
    "sale_listArt = salesForecast['FAMILY_ARTICLES'].tolist()\n",
    "data_listArt = all_formulationData['FAMILY_ARTICLES'].tolist()\n",
    "\n",
    "sale_listArt = lstNoDuplication(sale_listArt)\n",
    "data_listArt = lstNoDuplication(data_listArt)\n",
    "print([i for i in sale_listArt if i not in data_listArt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6c2bc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARIDA', 'Can Not Match The Name', 'ELLINGTON', 'EXPRESSE', 'LAOCAI', 'MADERA', 'MALDONADO', 'VINTAGE']\n"
     ]
    }
   ],
   "source": [
    "# CURRENT SALES ORDER INFACTORY\n",
    "\n",
    "# curretnOrders = pd.read_excel(open('L:\\\\PLANNING\\\\Lê Tín\\\\BACK-UP\\\\JBS Planning Next 2022.xlsx','rb'), sheet_name='Orders Plan')\n",
    "curretnOrders = pd.read_excel(open('C:\\\\Users\\danglc\\\\Desktop\\machineLearning\\\\JBS Planning Next 2023.xlsx','rb'), sheet_name='Orders Plan')\n",
    "curretnOrders_col = curretnOrders.columns.values.tolist()\n",
    "curretnOrders_col = list(map(lambda x: x.strip().upper(), sku_rate_col))\n",
    "curretnOrders.set_axis(sku_rate_col, axis='columns', inplace=True)\n",
    "# get out all the NaN from Sales Order Columns\n",
    "curretnOrders= curretnOrders[curretnOrders['S/O'].notnull()]\n",
    "\n",
    "# get three days ago timeline\n",
    "oneDaysAgo = datetime.now() - timedelta(days=1)\n",
    "\n",
    "# function to get the articles name\n",
    "def getArticles(data_df):\n",
    "    match_object = re.findall(r'\\w+-\\w\\s(\\w+-?\\w+)', data_df['ART.'])\n",
    "    if len(match_object)>0:\n",
    "        return match_object[0]\n",
    "    else:\n",
    "        return \"Can Not Match The Name\"\n",
    "curretnOrders['FAMILY_ARTICLES'] = curretnOrders.apply(getArticles, axis=1)\n",
    "\n",
    "# get neccessary column\n",
    "curretnOrders = curretnOrders[['FAMILY_ARTICLES', 'COLOR', 'SF (ALREADY +15%)','DE.DATE']]\n",
    "\n",
    "# convert to datetime\n",
    "curretnOrders['DE.DATE'] = pd.to_datetime(curretnOrders['DE.DATE'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# fill all NaT to current time\n",
    "curretnOrders[['DE.DATE']] = curretnOrders[['DE.DATE']].fillna(f'{datetime.now()}')\n",
    "\n",
    "# filter data from 3days ago onwards\n",
    "curretnOrders = curretnOrders.loc[curretnOrders['DE.DATE']>oneDaysAgo]\n",
    "\n",
    "# group the articles demand on articles name\n",
    "curretnOrders = pd.DataFrame({'CurrentOrders' : curretnOrders.groupby(['FAMILY_ARTICLES', 'COLOR'])['SF (ALREADY +15%)'].sum()}).reset_index()\n",
    "\n",
    "# Check if articles in sale  list in database\n",
    "def lstNoDuplication(x):\n",
    "  return list(dict.fromkeys(x))\n",
    "\n",
    "orders_listArt = curretnOrders['FAMILY_ARTICLES'].tolist()\n",
    "data_listArt = all_formulationData['FAMILY_ARTICLES'].tolist()\n",
    "\n",
    "orders_listArt = lstNoDuplication(orders_listArt)\n",
    "data_listArt = lstNoDuplication(data_listArt)\n",
    "print([i for i in orders_listArt if i not in data_listArt])\n",
    "\n",
    "# ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1660d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COORECTION ON THE ARTICLE NAME IF IT MISMATCH COMPARING TO DATABASE\n",
    "order_missArt_lst = ['ELLI','VINT', 'MALD','EXPRESS']\n",
    "def matcher(col):\n",
    "    for i in order_missArt_lst:\n",
    "        if i.upper() in col:\n",
    "            return i\n",
    "    else:\n",
    "        return col\n",
    "curretnOrders['FAMILY_ARTICLES'] = curretnOrders['FAMILY_ARTICLES'].apply(matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bc6804a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARIDA', 'Can Not Match The Name', 'LAOCAI', 'MADERA']\n"
     ]
    }
   ],
   "source": [
    "# CHECK CURRENT SALES AFTER AGLIGNED WITH DATABASE\n",
    "def lstNoDuplication(x):\n",
    "  return list(dict.fromkeys(x))\n",
    "\n",
    "orders_listArt = curretnOrders['FAMILY_ARTICLES'].tolist()\n",
    "data_listArt = all_formulationData['FAMILY_ARTICLES'].tolist()\n",
    "\n",
    "orders_listArt = lstNoDuplication(orders_listArt)\n",
    "data_listArt = lstNoDuplication(data_listArt)\n",
    "print([i for i in orders_listArt if i not in data_listArt])\n",
    "\n",
    "# ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e549bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET HISTORYCONSUMPTION\n",
    "historyConsumption = pd.read_csv('C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\historyConsumption.csv', encoding='cp1252')\n",
    "historyConsumption['Mon_Year'] = historyConsumption['Mon_Year'].apply(lambda x: x.upper())\n",
    "\n",
    "# Functions to get last 6 months as format in data\n",
    "def convertNumToMonth(num):\n",
    "    if num == -5:\n",
    "        mth= 'JUL'\n",
    "    if num == -4:\n",
    "        mth= 'AUG'\n",
    "    if num == -3:\n",
    "        mth= 'SEP'\n",
    "    if num == -2:\n",
    "        mth= 'OCT'\n",
    "    if num == -1:\n",
    "        mth= 'NOV'\n",
    "    if num == 0:\n",
    "        mth= 'DEC'\n",
    "    if num == 1:\n",
    "        mth= 'JAN'\n",
    "    if num == 2:\n",
    "        mth= 'FEB'\n",
    "    if num == 3:\n",
    "        mth= 'MAR'\n",
    "    if num == 4:\n",
    "        mth= 'APR'\n",
    "    if num == 5:\n",
    "        mth= 'MAY'\n",
    "    if num == 6:\n",
    "        mth= 'JUN'\n",
    "    if num == 7:\n",
    "        mth= 'JUL'\n",
    "    if num == 8:\n",
    "        mth= 'AUG'\n",
    "    if num == 9:\n",
    "        mth= 'SEP'\n",
    "    if num == 10:\n",
    "        mth= 'OCT'\n",
    "    if num == 11:\n",
    "        mth= 'NOV'\n",
    "    if num == 12:\n",
    "        mth= 'DEC'\n",
    "    return mth\n",
    "def getLast6months(tuday):\n",
    "    mth = tuday.month\n",
    "    yr = tuday.year\n",
    "    m1,m2,m3,m4,m5,m6 = mth-1, mth-2, mth-3, mth-4, mth-5,mth-6\n",
    "    lst6mth = [m1,m2,m3,m4,m5,m6]\n",
    "    lst6mth = sorted(lst6mth, reverse=False)\n",
    "#     return lst6mth\n",
    "    lstyr =[]\n",
    "    for mth in lst6mth:\n",
    "        mth_intext = convertNumToMonth(mth)\n",
    "        if mth > 0:\n",
    "            yrConvert=str(yr)[-2:]\n",
    "        else:\n",
    "            yrConvert = str(yr-1)[-2:]\n",
    "        lstyr.append(f'{mth_intext}_{yrConvert}')\n",
    "    return lstyr\n",
    "# get last 6 month Consumption\n",
    "last_6mth = getLast6months(date.today())\n",
    "lst6mth_Consumption = historyConsumption[historyConsumption['Mon_Year'].isin(last_6mth)]\n",
    "\n",
    "# get last 6 month consumption as horizontal view\n",
    "lst6mth_Consumption_horizontal = pd.pivot_table(lst6mth_Consumption, index= ['Material', 'Component_Description'], columns=['Mon_Year'], values=['Consumption'], aggfunc = 'sum', fill_value = 0 )\n",
    "lst6mth_Consumption_horizontal.columns = lst6mth_Consumption_horizontal.columns.droplevel(0)\n",
    "lst6mth_Consumption_horizontal = lst6mth_Consumption_horizontal.reset_index().rename_axis(None, axis=1)\n",
    "lst = [\"Material\", \"Component_Description\"]\n",
    "for col in last_6mth:\n",
    "    lst.append(col)\n",
    "lst6mth_Consumption_horizontal = lst6mth_Consumption_horizontal[lst]\n",
    "lst6mth_Consumption_horizontal.to_csv(f\"C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\RunSolveFile\\\\History_Consumption.csv\")\n",
    "\n",
    "#Get chemical MonthlyConsumption\n",
    "col_list = lst6mth_Consumption[[\"Mon_Year\"]]\n",
    "col_list = col_list.drop_duplicates(subset= ['Mon_Year'], keep='first', inplace=False)\n",
    "col_list_count = col_list['Mon_Year'].count()\n",
    "hisConsumption = pd.DataFrame({'monthly Consumption (6months)' : round(lst6mth_Consumption.groupby(['Material'])['Consumption'].sum()/col_list_count,0)}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe25f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET UPDATE FOR INTRANSIT\n",
    "ETA_update = pd.read_excel(open('C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\Chemical planning 2023.xls','rb'), sheet_name='Sheet1')\n",
    "\n",
    "# get out all the NaN from Code\n",
    "ETA_update = ETA_update[ETA_update['Code'].notnull()]\n",
    "\n",
    "# get columns list\n",
    "ETA_columns = ETA_update.columns.tolist()\n",
    "\n",
    "# trim all columns and assign back to dataframe\n",
    "ETA_columns = [col.strip() for col in ETA_columns]\n",
    "ETA_update.set_axis(ETA_columns, axis=1, inplace=True)\n",
    "ETA_update = ETA_update.loc[ETA_update['Shoe/Fur']=='Fur']\n",
    "\n",
    "# change data type of \"ETA Vietnam PORT\" to string\n",
    "ETA_update = ETA_update.astype({'ETA Vietnam PORT':'str', 'Shipping Qty':'str'})\n",
    "\n",
    "# combine quantity with ETA\n",
    "ETA_update['toVNport'] = ETA_update[[\"ETA Vietnam PORT\", \"Shipping Qty\"]].apply(\"::\".join, axis=1)\n",
    "\n",
    "# convert back Shipping Qty back to float\n",
    "ETA_update = ETA_update.astype({'Shipping Qty':'float'})\n",
    "\n",
    "# combine all ETA in one row and group all same chemical\n",
    "ETA_quantity = ETA_update.groupby(['Code'])['Shipping Qty'].sum().reset_index()\n",
    "ETA_shipment = ETA_update.groupby(['Code'])['toVNport'].apply(lambda x: '|||'.join(x)).reset_index()\n",
    "\n",
    "# combine all ETA, quantity for one chemical\n",
    "ETA_allCombine = ETA_quantity.merge(ETA_shipment, how='left', on=['Code'])\n",
    "ETA_allCombine.set_axis(['Material','Intransit', 'Intransit_Notes'], axis=1, inplace=True)\n",
    "# --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6302a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET CHEMICAL STOCK\n",
    "chemicalStock = pd.read_csv('C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\chemicalStock.csv', encoding='cp1252')\n",
    "#Get chemical stock\n",
    "chemicalStock = chemicalStock[['Material', 'Storage Location', 'Long Material Description', 'Unrestricted']]\n",
    "chemicalStock = chemicalStock[chemicalStock['Material'] < 1700000]\n",
    "chemicalStock_CH01 = chemicalStock[chemicalStock['Storage Location'] == 'CH01']\n",
    "chemicalStock_CH01 = pd.DataFrame({'Stock_CH01' : round(chemicalStock_CH01.groupby(['Material'])['Unrestricted'].sum(),0)}).reset_index()\n",
    "chemicalStock_CH10 = chemicalStock[chemicalStock['Storage Location'] == 'CH10']\n",
    "chemicalStock_CH10 = pd.DataFrame({'Stock_CH10' : round(chemicalStock_CH10.groupby(['Material'])['Unrestricted'].sum(),0)}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0233433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE SALES FORECAST TO OUR DATABASE\n",
    "formulation_Forecast = all_formulationData.merge(salesForecast, how='left', left_on=['FAMILY_ARTICLES', 'colorCode'], right_on=['FAMILY_ARTICLES', 'COLOR'])\n",
    "# formulation_Forecast.to_csv(f\"C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\all_formulationDataForecast.csv\")\n",
    "\n",
    "# MERGE CURRENT SALES ORDERS TO OUR DATABASE, SALES FORECAST\n",
    "formulation_Forecast_CurrentOrder = formulation_Forecast.merge(curretnOrders, how='left', left_on=['FAMILY_ARTICLES', 'colorCode'], right_on=['FAMILY_ARTICLES', 'COLOR'])\n",
    "# formulation_Forecast_CurrentOrder.to_csv(f\"C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\formulation_Forecast_CurrentOrder.csv\")\n",
    "\n",
    "# CALCULATE MONTHLY CHEMICAL FORECAST AND CURRENT CHEMICAL DEMAND\n",
    "formulation_Forecast_CurrentOrder['monthly Chemical Forecast'] = round((formulation_Forecast_CurrentOrder['G_sf']*formulation_Forecast_CurrentOrder['monthlyFORECAST']/1000)*(formulation_Forecast_CurrentOrder['Component quantityy']*formulation_Forecast_CurrentOrder['PIGCOM_RATE']/1000),3)\n",
    "formulation_Forecast_CurrentOrder['current Chemical Demand'] = round((formulation_Forecast_CurrentOrder['G_sf']*formulation_Forecast_CurrentOrder['CurrentOrders']/1000)*(formulation_Forecast_CurrentOrder['Component quantityy']*formulation_Forecast_CurrentOrder['PIGCOM_RATE']/1000),3)\n",
    "formulation_Forecast_CurrentOrder.to_csv(f\"C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\RunSolveFile\\\\all_formulationDataForecastCurOrder.csv\")\n",
    "\n",
    "# MONTHLY CHEMICAL FORECAST, DEMAND BY EACH CHEMICAL COMBINE\n",
    "monthly_ChemicalForecast = pd.DataFrame({'monthly Chemical Forecast' : round(formulation_Forecast_CurrentOrder.groupby(['Componenty', 'PIGCOM'])['monthly Chemical Forecast'].sum(),0)}).reset_index()\n",
    "monthly_ChemicalDemand = pd.DataFrame({'current Chemical Demand' : round(formulation_Forecast_CurrentOrder.groupby(['Componenty'])['current Chemical Demand'].sum(),0)}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0e998745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE ALL THINGS TOGETHER\n",
    "# read Chemical Control file\n",
    "chemicalInfo = pd.read_csv('C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\CHEMICAL CONTROL.csv', encoding='cp1252')\n",
    "\n",
    "# combine intransit infor to Chemical Control\n",
    "chemicalInfo_Intransit = chemicalInfo.merge(ETA_allCombine, how='left', on=['Material'])\n",
    "\n",
    "# combine stock CH10, CH01 infor to Chemical Control\n",
    "chemicalInfo_Intransit_curStock = chemicalInfo_Intransit.merge(chemicalStock_CH01, how='left', on=['Material'])\n",
    "chemicalInfo_Intransit_curStock = chemicalInfo_Intransit_curStock.merge(chemicalStock_CH10, how='left', on=['Material'])\n",
    "\n",
    "# combine monthly Chemical Forecast and monthly Chemical Demand forecast to chemicalInfo\n",
    "chemicalInfo_Intransit_curStock_Forecast = chemicalInfo_Intransit_curStock.merge(monthly_ChemicalForecast, how='left', left_on=['Material'], right_on=['Componenty'])\n",
    "chemicalInfo_Intransit_curStock_Forecast_curDemand = chemicalInfo_Intransit_curStock_Forecast.merge(monthly_ChemicalDemand, how='left', left_on=['Material'], right_on=['Componenty'])\n",
    "chemicalInfo_Intransit_curStock_Forecast_curDemand = chemicalInfo_Intransit_curStock_Forecast_curDemand.drop(['Componenty_x', 'Componenty_y'], axis=1)\n",
    "\n",
    "# combine monthly history Chemical Consumption to chemical Info\n",
    "chemicalInfo_Intransit_curStock_Forecast_curDemand_Consumption = chemicalInfo_Intransit_curStock_Forecast_curDemand.merge(hisConsumption, how='left', on=['Material'])\n",
    "\n",
    "# ALL DATA\n",
    "allData = chemicalInfo_Intransit_curStock_Forecast_curDemand_Consumption\n",
    "allData.to_csv(f\"C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\RunSolveFile\\\\AllData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9791f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULATE PROPOSAL\n",
    "# fill NaN with 0,-\n",
    "allData[[\"Leadtime\",\"Intransit\",\"Stock_CH01\",\"Stock_CH10\",\"monthly Chemical Forecast\", \"monthly Consumption (6months)\",\"current Chemical Demand\"]] = allData[[\"Leadtime\",\"Intransit\",\"Stock_CH01\",\"Stock_CH10\",\"monthly Chemical Forecast\", \"monthly Consumption (6months)\",\"current Chemical Demand\"]].fillna(0)\n",
    "allData[[\"PIGCOM\", \"Intransit_Notes\", \"Comments\"]] = allData[[\"PIGCOM\", \"Intransit_Notes\", \"Comments\"]].fillna('-')\n",
    "\n",
    "# define either forecast or consumption as standard\n",
    "conditions = [\n",
    "    (allData['monthly Chemical Forecast'] >= allData['monthly Consumption (6months)']),\n",
    "    (allData['monthly Chemical Forecast'] < allData['monthly Consumption (6months)']),\n",
    "]\n",
    "\n",
    "# proposal Consumption balance btw forecast & consumption\n",
    "results_monthStandard = [allData['monthly Chemical Forecast'],\n",
    "                                allData['monthly Consumption (6months)']]\n",
    "\n",
    "allData['ForeCast Consump.'] = np.select(conditions, results_monthStandard)\n",
    "\n",
    "# Default minumum Stockf (round up to month and plus 1.5)\n",
    "def minStock(data_df):\n",
    "    if data_df['ForeCast Consump.'] == 0:\n",
    "        return 0\n",
    "    elif data_df['ForeCast Consump.'] != 0:\n",
    "        return round(data_df['Leadtime']/30 + 3, 1)\n",
    "    \n",
    "allData['StockSet InHouse & Intransit'] = allData.apply(minStock, axis = 1)\n",
    "# chemicalData_Info_Intransit_Forecast_Consumption['minimumStock_inMonth'] = np.ceil(chemicalData_Info_Intransit_Forecast_Consumption['Leadtime']/30) + 1.5\n",
    "\n",
    "# Current Stock\n",
    "def currentStock(data_df):\n",
    "    if data_df['ForeCast Consump.'] == 0:\n",
    "        return data_df['Stock_CH01']+data_df['Stock_CH10']+data_df['Intransit']\n",
    "    elif data_df['ForeCast Consump.'] != 0:\n",
    "        return round((data_df['Stock_CH01']+data_df['Stock_CH10']+data_df['Intransit'])/data_df['ForeCast Consump.'], 1)\n",
    "\n",
    "allData['Current Stock InMonth'] = allData.apply(currentStock, axis = 1)\n",
    "# chemicalData_Info_Intransit_Forecast_Consumption['CurrentStockInMonth'] = round((chemicalData_Info_Intransit_Forecast_Consumption['Stock_CH01']+chemicalData_Info_Intransit_Forecast_Consumption['Stock_CH10']+chemicalData_Info_Intransit_Forecast_Consumption['Intransit'])/chemicalData_Info_Intransit_Forecast_Consumption['ForeCast_Consumption'], 1)\n",
    "\n",
    "# BuyToHitMinimumStock\n",
    "allData['Buy To StockSet'] = (allData['StockSet InHouse & Intransit'] - allData['Current Stock InMonth'])*allData['ForeCast Consump.']\n",
    "allData['Buy To StockSet'] = allData['Buy To StockSet'].apply(lambda x: x if (x>0) else 0)\n",
    "allData['ByTank'] = round(allData['Buy To StockSet']/allData['Tank_Drum_Size'],1)\n",
    "\n",
    "# current Stock vs current orders\n",
    "allData['curStock vs. curOrders'] = round(allData['Stock_CH01']+allData['Stock_CH10']-allData['current Chemical Demand'],0)\n",
    "allData['curStock vs. oneMonth'] = round(allData['Stock_CH01']+allData['Stock_CH10']-allData['ForeCast Consump.'],0)\n",
    "\n",
    "\n",
    "# InHouse Stock\n",
    "def inhouseStock(data_df):\n",
    "    if data_df['ForeCast Consump.'] == 0:\n",
    "        return data_df['Stock_CH01']+data_df['Stock_CH10']\n",
    "    elif data_df['ForeCast Consump.'] != 0:\n",
    "        return round((data_df['Stock_CH01']+data_df['Stock_CH10'])/data_df['ForeCast Consump.'], 1)\n",
    "# InHouse Stock\n",
    "allData['InHouse Stock InMonth'] = allData.apply(inhouseStock, axis = 1)\n",
    "\n",
    "\n",
    "allData.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "allData[[\"Current Stock InMonth\"]] = allData[[\"Current Stock InMonth\"]].fillna(0)\n",
    "allData['revised To Buy'] = ''\n",
    "allData['stock included Buy'] = ''\n",
    "allData = allData[['Material', 'Long Material Description','Supplier','Location', 'PIGCOM','Comments', 'Leadtime', 'Tank_Drum_Size', 'Intransit','Intransit_Notes','Stock_CH01','Stock_CH10', 'monthly Chemical Forecast','monthly Consumption (6months)', 'InHouse Stock InMonth','StockSet InHouse & Intransit','Current Stock InMonth','Buy To StockSet','ByTank', 'revised To Buy', 'stock included Buy', 'ForeCast Consump.', 'current Chemical Demand', 'curStock vs. curOrders', 'curStock vs. oneMonth']]\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d_%m_%Y%H%M%S\")\n",
    "\n",
    "allData.to_csv(f\"C:\\\\Users\\\\danglc\\\\Desktop\\\\machineLearning\\\\RunSolve\\\\Consolidation_{dt_string}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b69954f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
